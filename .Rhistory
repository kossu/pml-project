setwd("~/Google Drive/Data Science/02 - R Programming")
read.csv(hw1_data.csv)
dir()
read.csv("hw1_data.csv"")
""
read.csv("hw1_data.csv")
data <- read.csv("hw1_data.csv")
head(data)
data[1:2,]
dim(data)
data[151:153,]
data[152:153,]
data[47,]
mo <- is.na(data$Ozone)
sum(mo)
mean(mo)
mean(data[!mo])
mean(data[!mo,])
ave <- data[,3 & !mo]
ave <- data[,3&!mo]
ave <- data[!mo]
ave <- data[,!mo]
mo
ave <- data[,mo]
data2 <- data[!mo]
data2 <- data[!mo,]
data2
mean(data2@Ozone)
mean(data2)
data3 <- data2$Ozone
mean(data3)
data10 <- data[Ozone>31]
data2
data10 <- data2[Ozone>31]
data10 <- data2["Ozone">31]
data11 <- data10("Temp">90)
data11 <- data10["Temp">90]
data12 <- data11$Solar.R
mean(data12)
mean(data12,na.rm=TRUE)
?complete.cases
d1 <- data$Ozone
d2 <- data$Solar.R
complete.cases(d1,d2)
d3 <- complete.cases(d1,d2)
d5data[d3]
d5data-> data[d3]
d5data <- data[d3]
d5data <- data[d3,]
d5data
d20 <- d5data[Ozone > 31]
d20 <- d5data["Ozone"" > 31]
d20 <- d5data["Ozone"" > 31]"
d20 <- d5data["Ozone" > 31]"
""
d20 <- d5data["Ozone" > 31]
d30 <- d20["Temp">90]
d30
d40 <- d30$Solar.R
mean(d40)
june <- data[Month=6]
june <- data["Month"=6]
june <- data["Month"==6]
june
june <- data["Month"=6]
june <- data["Month"=6,]
june <- data["Month"==6]
june
june <- data[,4:5]
june
june2 <- june[month=6]
june2 <- june["Month"=6]
june2 <- june["Month" = 6]
june2 <- june[32:61,]
mean(june2$Temp)
max(data[Month=5, Ozone])
ma <- data["Month"=5]
ma <- data[Month=5]
ma <- data["Month"="5"]
ma <- data["Month"==5]
ma
data
ma data(1:31,)
ma data[1:31,]
ma <-data[1:31,]
ma
max(ma$Ozone)
ma2 <- ma[is.na(ma$Ozone)]
ma2 <- ma[,is.na(ma$Ozone)]
ma2 <- ma[is.na(ma$Ozone),]
max(ma2$Ozone)
ma2
ma3 <- ma[!ma2]
max(ma3$Ozone)
ma3
ma <- data[data$Month=5]
ma <- data[data$Month==5]
ma <- data[data$Month==5,]
ma
bad <- is.na(ma$Ozone)
ma1 <- ma[!bad]
ma1 <- ma[!bad,1]
ma1
mean(ma)
mean(ma1)
max(ma1)
x <- c(4, TRUE)
class(x)
x <- list(2, "a", "b", TRUE)
x[[2]]
x <- 1:4
y <- 2:
3
y <- 2:3
x+y
s <- x+y
class(s)
x <- c(3, 5, 1, 10, 12, 6)
head(data)
data[1:2,]
tail(data)
data[152:,]
data[152:155,]
data[47,]
ozo <- data[,1]
is.na(ozo)
sum(is.na(ozo))
153-37
ozo
bad <- is.na(ozo)
ozomean <- ozo[!bad]
mean(ozomean)
d1 <- data[data$Ozone>31 & data$Temp >90]
d1 <- data[,data$Ozone>31 & data$Temp >90]
d1 <- data[data$Ozone>31 & data$Temp >90,]
d1
mean(d1$Solar.R)
?mean
mean(d1$Solar.R,na.rm=true)
mean(d1$Solar.R, na.rm=true)
mean(d1$Solar.R, na.rm=TRUE)
temp <- data[data$Month=6]
temp <- data[data$Month=6,]
temp <- data[data$Month==6]
temp <- data[data$Month==6,4]
temp
mean(temp)
ozo <- data[data$Month==5,1]
ozo
rm(list=ls())
getwd()
dir()
read.csv("hw1_data.csv")
data <- read.csv("hw1_data.csv")
head(data)
june <- data[,5==5]
june
june <- data[,"5"==5]
june <- data[5==5,]
head(june)
tail(june)
june <- data[,5]
tail(june)
june <- data[data$Month==6]
june <- data[data$Month==6,]
june
rm(list=ls())
library(datasets)
data("iris")
sapply(split(iris, iris$Species), mean)
sapply(split(iris, iris$Species), mean, na.rm = TRUE)
split(iris, iris$Species)
spe <- split(iris, iris$Species)
summary(spe)
sapply(spe[3], mean)
sapply(spe, mean)
split(iris, iris$Sepal.Length)
spe <- split(iris, iris$Species)
spe[3]
sapply(spe[3], mean)
lapply(spe[3], mean)
tapply(spe[3], 2, mean)
tapply(iris, iris$Species, mean)
spe <- split(iris, iris$Species)
summary(spe)
sp <- split(spe, spe$virginica)
q
exit
sp <- spe[3]
sp
sapply(sp, mean)
sapply(sp[,3], mean)
head(sp)
colMeans(sp)
spe < split(iris, iris$Species)
spe <- split(iris, iris$Species)
tapply(iris, iris$Species, mean)
tapply(iris$Sepal.Length, iris$Species, mean)
apply(iris[,1:4],2,mean)
data("mtcars")
sapply(split(mtcars$mpg, mtcars$cyl), mean)
?with
with(mtcars, tapply(mpg, cyl, mean))
tapply(mtcars$mpg, mtcars$cyl, mean)
tapply(mtcars$hp, mtcars$cyl, mean)
d <- tapply(mtcars$hp, mtcars$cyl, mean)
d[3]-d[1]
with(mtcars, tapply(mpg, cyl, mean))
sapply(mtcars, cyl, mean)
tapply(mtcars$mpg, mtcars$cyl, mean)
mean(mtcars$mpg, mtcars$cyl)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
tapply(mtcars$cyl, mtcars$mpg, mean)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
rm(list=ls())
x <- matrix(1:20,5)
x
solve(x)
x <- matrix(1:25,5)
solve(x)
x <- matrix(5:30,5)
x <- matrix(5:29,5)
solve(x)
x <- matrix(runif(9),3)
solve(x)
source('~/Google Drive/Data Science/git/ProgrammingAssignment2/cachematrix.R')
cacheSolve(x)
x
makeCacheMatrix <- function(x = matrix()) {
m <- NULL
# set value of matrix
set <- function(y) {
x <<- y
m <<- NULL
}
#get value of matrix
get <- function() x
setinv <- function(solve) m <<- mean
getinv <- function() m
list(set = set, get = get,
setinv = setinv,
getinv = getinv)
}
cacheSolve(x)
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
m <- x$getinv()
# if m is not empty, it's used
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- solve(data, ...)
x$setinv(m)
m
}
cacheSolve(x)
cacheSolve(matrix(3,4,2,1))
library(xlsx)
library(rJava)
install.packages("xlsx")
library(rJava)
install.packages("rJava")
library(xlsx)
install.packages("xlsx")
remove.packages(rJava)
remove.packages("rJava")
remove.packages("xlsx")
rm=(list=ls())
rm(list=ls())
source('~/.active-rstudio-document')
sd1 <- 4
m1 <- 0
x <- seq(-4, 4, length=100)
?dist
?ndist
?dnorm
nd1 <- dnorm(m1, sd1)
nd1 <- dnorm(x, m1, sd1)
plot(x,ndx, type="l", lty=2, xlab="x value",
ylab="Density", main="Normaalijakaumia eri keskihajonnalla"))
plot(x, ndx1 type="l", lty=2, xlab="x value",
ylab="Density", main="Normaalijakaumia eri keskihajonnalla")
plot(x, ndx1, type="l", lty=2, xlab="x value",
ylab="Density", main="Normaalijakaumia eri keskihajonnalla")
plot(x, nd1, type="l", lty=2, xlab="x value",
ylab="Density", main="Normaalijakaumia eri keskihajonnalla")
sd1 <- 1
x <- seq(-4, 4, length=100)
nd1 <- dnorm(x, m1, sd1)
plot(x, nd1, type="l", lty=2, xlab="x value",
ylab="Density", main="Normaalijakaumia eri keskihajonnalla")
sd2 <- 3
m2 <- 0
nd2 <- dnorm(x, m2, sd2)
?dt
lines(x, dnorm(x, m2, sd2), lwd=2, col=1)
sd2 <- 2
lines(x, dnorm(x, m2, sd2), lwd=2, col=1)
sd2 <- 1.5
lines(x, dnorm(x, m2, sd2), lwd=2, col=1)
sd1 <- 3
sd2 <- 5
m1 <- 10
m2 <- 10
x <- seq(-4, 4, length=100)
nd1 <- dnorm(x, m1, sd1)
nd2 <-
plot(x, nd1, type="l", lty=2, xlab="x value",
ylab="Density", main="Normaalijakaumia eri keskihajonnalla")
lines(x, dnorm(x, m2, sd2), lwd=2, col=1)
sd1 <- 1
sd2 <- 1.2
m1 <- 0
m2 <- 0
x <- seq(-4, 4, length=100)
nd1 <- dnorm(x, m1, sd1)
nd2 <-
plot(x, nd1, type="l", lty=2, xlab="x value",
ylab="Density", main="Normaalijakaumia eri keskihajonnalla")
lines(x, dnorm(x, m2, sd2), lwd=2, col=1)
sd2 <- 1.5
lines(x, dnorm(x, m2, sd2), lwd=2, col=1)
# normal dist -
#
sd1 <- 4
sd2 <- 6
m1 <- 0
m2 <- 0
x <- seq(-8, 8, length=100)
nd1 <- dnorm(x, m1, sd1)
nd2 <-
plot(x, nd1, type="l", lty=2, xlab="x value",
ylab="Density", main="Normaalijakaumia eri keskihajonnalla")
lines(x, dnorm(x, m2, sd2), lwd=2, col=1)
# normal dist -
#
sd1 <- 1
sd2 <- 1.5
m1 <- 0
m2 <- 0
x <- seq(-4, 4, length=100)
nd1 <- dnorm(x, m1, sd1)
nd2 <-
plot(x, nd1, type="l", lty=2, xlab="x value",
ylab="Density", main="Normaalijakaumia eri keskihajonnalla")
lines(x, dnorm(x, m2, sd2), lwd=2, col=1)
# normal dist -
#
sd1 <- 1
sd2 <- 1.5
m1 <- 0
m2 <- 0
x <- seq(-4, 4, length=100)
nd1 <- dnorm(x, m1, sd1)
nd2 <-
plot(x, nd1, type="l", lty=2, xlab="x value",
ylab="Density", main="Standardoitu norm.jak. (keskihajonta 1 & 1.5)")
lines(x, dnorm(x, m2, sd2), lwd=2, col=1)
lines(x, dnorm(x, m2, sd2), lwd=2, col=3)
lines(x, dnorm(x, m2, sd2), lwd=2, col=2)
plot(x, nd1, type="l", lty=2, xlab="x value", col="1"
ylab="Density", main="Standardoitu norm.jak. (keskihajonta 1 & 1.5)")
plot(x, nd1, type="l", lty=2, xlab="x value", col="1",
ylab="Density", main="Standardoitu norm.jak. (keskihajonta 1 & 1.5)")
lines(x, dnorm(x, m2, sd2), lwd=2, col=2)
plot(x, nd1, type="l", lty=2, xlab="x value", col="4",
ylab="Density", main="Standardoitu norm.jak. (keskihajonta 1 & 1.5)")
plot(x, nd1, type="l", lty=2, xlab="x value", col="4", lwd=2
ylab="Density", main="Standardoitu norm.jak. (keskihajonta 1 & 1.5)")
plot(x, nd1, type="l", lty=2, xlab="x value", col="4", lwd=2,
ylab="Density", main="Standardoitu norm.jak. (keskihajonta 1 & 1.5)")
lines(x, dnorm(x, m2, sd2), lwd=2, col=2)
plot(x, nd1, type="l", xlab="x value", col="4", lwd=2,
ylab="Density", main="Standardoitu norm.jak. (keskihajonta 1 & 1.5)")
lines(x, dnorm(x, m2, sd2), lwd=2, col=2,lty=2)
plot(x, nd1, type="l", xlab="x value", col="4", lwd=2,
ylab="Density", main="Standardoitu normaali jakauma", sub="(keskihajonta 1 & 1.5)")
plot(x, nd1, type="l", xlab="x value", col="4", lwd=2,
ylab="Density", main="Standardoitu norm.jak. (keskihajonta 1 & 1.5)")
lines(x, dnorm(x, m2, sd2), lwd=2, col=2,lty=2)
# normal dist -
#
m1 <- 0
sd1 <- 1
m2 <- 0
sd2 <- 1.5
x <- seq(-4, 4, length=100)
nd1 <- dnorm(x, m1, sd1)
plot(x, nd1, type="l", xlab="x", col="4", lwd=2,
ylab="Tiheys", main="Standardoitu normaali jakauma (sd 1 & 1.5)")
lines(x, dnorm(x, m2, sd2), lwd=2, col=2, lty=2)
sd2 <- 1.3
lines(x, dnorm(x, m2, sd2), lwd=2, col=2, lty=2)
sd2 <- 1.2
lines(x, dnorm(x, m2, sd2), lwd=2, col=2, lty=2)
# normal dist -
#
m1 <- 0
sd1 <- 1
m2 <- 0
sd2 <- 1.2
x <- seq(-4, 4, length=100)
nd1 <- dnorm(x, m1, sd1)
plot(x, nd1, type="l", xlab="x", col="4", lwd=2,
ylab="Tiheys", main="Standardoitu normaali jakauma (sd 1 & 1.5)")
lines(x, dnorm(x, m2, sd2), lwd=2, col=2, lty=2)
# normal dist -
#
m1 <- 0
sd1 <- 1
m2 <- 0
sd2 <- 1.2
x <- seq(-4, 4, length=100)
nd1 <- dnorm(x, m1, sd1)
plot(x, nd1, type="l", xlab="x", col="4", lwd=2,
ylab="Tiheys", main="Standardoitu normaali jakauma (sd 1 & 1.2)")
lines(x, dnorm(x, m2, sd2), lwd=2, col=2, lty=2)
rm(list=ls())
# normal dist -
#
m1 <- 0
sd1 <- 1
m2 <- 0
sd2 <- 1.2
x <- seq(-4, 4, length=100)
nd1 <- dnorm(x, m1, sd1)
plot(x, nd1, type="l", xlab="x", col="4", lwd=2,
ylab="Tiheys", main="Standardoitu normaali jakauma (sd 1 & 1.2)")
lines(x, dnorm(x, m2, sd2), lwd=2, col=2, lty=2)
install.packages(c("chron", "curl", "data.table", "dplyr", "lme4", "mgcv", "quantmod", "Rcpp", "rJava", "tidyselect"))
rm(list=ls())
mod1
# practical machine learning - project
#
# original data http://groupware.les.inf.puc-rio.br/har#weight_lifting_exercises
#
# "Six young health participants were asked to perform one set of 10
# repetitions of the Unilateral Dumbbell Biceps Curl in five
# different fashions: exactly according to the specification
# (Class A), throwing the elbows to the front (Class B), lifting
# the dumbbell only halfway (Class C), lowering the dumbbell only
# halfway (Class D) and throwing the hips to the front (Class E)."
#
# pml course notes: http://sux13.github.io/DataScienceSpCourseNotes/8_PREDMACHLEARN/Practical_Machine_Learning_Course_Notes.html
# caret help: https://topepo.github.io/caret/model-training-and-tuning.html
#
rm(list=ls())
library(doMC)
registerDoMC(cores = 2)
library(caret)
set.seed(56789)
setwd("~/Google Drive/Data Science/git/pml")
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
# clean up data: change other than Y into numeric format, remove NAs
y <- training$classe # copy Y
training <- training[,-c(1:7, 160)] # drop X, timestamps, windows etc... AND Y!!!
training <- data.frame(apply(training, 2, function(x) as.numeric(x))) # change into numeric format
training$classe <- y # add back Y
nas <- apply(training, 2, function(x) mean(is.na(x))) # % of NAs in cols
ind <- 0.50 > nas # index of all where less than X % NAS
training <- training[,ind] # drop all but indexed columns
rm(list=c("ind", "nas", "y")) #cleanup
# testing: no need to remove unused columns, just making sure data is numeric
testing <- data.frame(apply(testing, 2, function(x) as.numeric(x))) # change into numeric format
# split data, 75 % train 25 % test
inTrain <- createDataPartition(training$classe,p=0.75, list=FALSE)
tra <- training[inTrain,] # training set
tes <- training[-inTrain,] # testing set
rm("inTrain") # cleanup
# build  models
#
# 1. Boosting (with 5-fold cross validation repeated 10 times)
tc1 <- trainControl(method = "repeatedcv", number = 5, repeats = 10) # trainControl args
f1 <- train(classe ~., "gbm", data = tra,
trControl = tc1)
f1$finalModel # print final model
pr1 <- predict(f1, tes) # predictions for model 1
mod1 <- confusionMatrix(pr1, tes$classe)$overall[1] # model 1
plot(f1)
library(doMC)
registerDoMC(cores = 2)
library(caret)
set.seed(56789)
setwd("~/Google Drive/Data Science/git/pml")
training <- training[,-c(1:7, 160)] # drop X, timestamps, windows etc... AND Y!!!
training <- data.frame(apply(training, 2, function(x) as.numeric(x))) # change into numeric format
training$classe <- y # add back Y
rm(list=ls())
library(doMC)
registerDoMC(cores = 2)
library(caret)
set.seed(56789)
setwd("~/Google Drive/Data Science/git/pml")
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")
y <- training$classe # copy Y
training <- training[,-c(1:7, 160)] # drop X, timestamps, windows etc... AND Y!!!
training <- data.frame(apply(training, 2, function(x) as.numeric(x))) # change into numeric format
training$classe <- y # add back Y
nas <- apply(training, 2, function(x) mean(is.na(x))) # % of NAs in cols
ind <- 0.50 > nas # index of all where less than X % NAS
training <- training[,ind] # drop all but indexed columns
rm(list=c("ind", "nas", "y")) #cleanup
# 1. Boosting (with 5-fold cross validation repeated 10 times)
tc1 <- trainControl(method = "repeatedcv", number = 5, repeats = 10) # trainControl args
f1 <- train(classe ~., "gbm", data = tra,
trControl = tc1, verbose=FALSE)
f1
rm(list=ls())
